# NVIDIA T4 Benchmark Data
# 10 runs per configuration

GPU_NAME = "T4"
GPU_DISPLAY_NAME = "NVIDIA T4"

# ==============================================================================
# Element-wise Addition
# ==============================================================================
ADD_FP32 = {
    "unfused": [5.2, 5.0, 5.5, 75.3, 712.9, 7104.9],
    "unfused_std": [0.4, 0.3, 0.8, 0.7, 4.7, 2.1],
    "fused": [2.5, 2.7, 2.8, 44.5, 423.0, 4214.7],
    "fused_std": [0.2, 0.5, 0.5, 0.6, 3.0, 5.4],
    "speedup": [2.08, 1.90, 1.97, 1.69, 1.69, 1.69],
    "speedup_std": [0.14, 0.26, 0.05, 0.02, 0.00, 0.01],
    "bw_unfused": [4.0, 41.4, 378.0, 272.2, 287.3, 288.3],
    "bw_unfused_std": [0.3, 2.1, 42.6, 2.4, 1.9, 0.1],
    "bw_fused": [4.9, 47.2, 446.6, 276.0, 290.6, 291.6],
    "bw_fused_std": [0.3, 6.3, 51.1, 3.5, 2.1, 0.4],
}

ADD_FP16 = {
    "unfused": [5.2, 5.5, 5.6, 45.1, 406.6, 3924.6],
    "unfused_std": [0.6, 0.7, 1.8, 8.6, 51.5, 119.3],
    "fused": [2.6, 2.7, 2.9, 24.5, 221.4, 2132.3],
    "fused_std": [0.3, 0.3, 0.9, 4.4, 23.4, 0.8],
    "speedup": [2.00, 2.08, 1.95, 1.83, 1.84, 1.84],
    "speedup_std": [0.10, 0.29, 0.05, 0.03, 0.03, 0.06],
    "bw_unfused": [2.0, 18.8, 194.6, 232.4, 254.6, 261.1],
    "bw_unfused_std": [0.2, 2.3, 34.9, 30.1, 24.4, 7.4],
    "bw_fused": [2.4, 23.3, 227.3, 255.5, 279.8, 288.1],
    "bw_fused_std": [0.3, 2.6, 41.3, 31.4, 23.3, 0.1],
}

# ==============================================================================
# Fused Multiply-Add (FMA)
# ==============================================================================
FMA_FP32 = {
    "unfused": [5.0, 5.1, 5.3, 88.6, 845.5, 8418.4],
    "unfused_std": [0.2, 0.4, 0.1, 0.8, 3.2, 4.1],
    "fused": [2.5, 2.4, 3.1, 57.5, 552.3, 5509.7],
    "fused_std": [0.2, 0.1, 0.5, 0.3, 2.0, 1.4],
    "speedup": [1.99, 2.10, 1.77, 1.54, 1.53, 1.53],
    "speedup_std": [0.15, 0.15, 0.19, 0.01, 0.00, 0.00],
    "bw_unfused": [5.0, 48.6, 462.8, 277.5, 290.7, 291.9],
    "bw_unfused_std": [0.2, 3.5, 6.4, 2.4, 1.1, 0.1],
    "bw_fused": [6.6, 67.8, 545.2, 285.1, 296.6, 297.4],
    "bw_fused_std": [0.6, 3.6, 62.8, 1.7, 1.1, 0.1],
}

FMA_FP16 = {
    "unfused": [5.2, 5.5, 5.8, 49.1, 446.6, 4277.5],
    "unfused_std": [0.6, 0.9, 1.8, 8.0, 61.6, 44.0],
    "fused": [2.7, 2.7, 3.0, 30.8, 288.0, 2781.4],
    "fused_std": [0.3, 0.3, 1.0, 2.7, 18.7, 0.8],
    "speedup": [1.96, 2.08, 1.92, 1.59, 1.55, 1.53],
    "speedup_std": [0.09, 0.28, 0.16, 0.10, 0.10, 0.02],
    "bw_unfused": [2.4, 22.9, 222.0, 254.5, 278.7, 287.3],
    "bw_unfused_std": [0.2, 3.2, 41.2, 29.5, 28.5, 2.9],
    "bw_fused": [3.1, 31.4, 283.8, 267.6, 285.4, 294.5],
    "bw_fused_std": [0.3, 3.4, 50.2, 19.3, 15.9, 0.1],
}

# ==============================================================================
# ReLU
# ==============================================================================
RELU_FP32 = {
    "unfused": [7.6, 7.8, 8.3, 106.5, 1003.4, 9951.5],
    "unfused_std": [0.6, 0.7, 2.0, 1.7, 4.5, 2.9],
    "fused": [2.5, 2.9, 2.9, 44.7, 421.5, 4203.8],
    "fused_std": [0.3, 0.7, 0.7, 0.6, 0.8, 1.7],
    "speedup": [3.01, 2.79, 2.84, 2.38, 2.38, 2.37],
    "speedup_std": [0.14, 0.46, 0.06, 0.05, 0.01, 0.00],
    "bw_unfused": [3.8, 37.1, 357.3, 269.4, 285.8, 288.1],
    "bw_unfused_std": [0.3, 3.0, 54.3, 4.2, 1.3, 0.1],
    "bw_fused": [4.9, 44.7, 434.9, 274.9, 291.5, 292.3],
    "bw_fused_std": [0.4, 9.3, 67.2, 3.6, 0.6, 0.1],
}

RELU_FP16 = {
    "unfused": [7.9, 7.6, 8.1, 62.4, 596.6, 5803.6],
    "unfused_std": [0.7, 0.6, 1.8, 8.8, 71.6, 25.8],
    "fused": [2.5, 2.7, 2.8, 24.7, 218.4, 2165.8],
    "fused_std": [0.2, 0.5, 0.6, 3.7, 8.6, 0.9],
    "speedup": [3.10, 2.91, 2.86, 2.53, 2.73, 2.68],
    "speedup_std": [0.24, 0.42, 0.07, 0.05, 0.20, 0.01],
    "bw_unfused": [1.8, 18.9, 182.1, 233.0, 242.7, 247.0],
    "bw_unfused_std": [0.2, 1.3, 25.7, 24.3, 22.4, 1.1],
    "bw_fused": [2.4, 23.5, 223.2, 252.3, 281.7, 283.7],
    "bw_fused_std": [0.2, 3.5, 31.2, 28.2, 10.0, 0.1],
}

# ==============================================================================
# Map Reduce - Naive Implementation
# (No data provided - fill in when available)
# ==============================================================================
MAP_REDUCE_NAIVE_FP32 = {
    "unfused": [7.2, 27.0, 226.2, 2152.1, 20704.2, 207015.7],
    "unfused_std": [1.4, 6.0, 50.3, 253.5, 21.8, 82.8],
    "fused": [5.0, 25.1, 223.4, 2031.5, 20287.6, 202782.8],
    "fused_std": [1.0, 5.4, 49.3, 1.6, 21.3, 15.9],
    "speedup": [1.44, 1.07, 1.01, 1.06, 1.02, 1.02],
    "speedup_std": [0.04, 0.01, 0.00, 0.12, 0.00, 0.00],
    "bw_unfused": [2.3, 6.3, 7.5, 7.7, 7.9, 7.9],
    "bw_unfused_std": [0.3, 0.9, 1.1, 0.7, 0.0, 0.0],
    "bw_fused": [1.7, 3.4, 3.8, 4.0, 4.0, 4.0],
    "bw_fused_std": [0.2, 0.5, 0.5, 0.0, 0.0, 0.0],
}

MAP_REDUCE_NAIVE_FP16 = {
    "unfused": [326.8, 5500.7, 30335.8, 31015.8, 37385.4, 100597.6],
    "unfused_std": [79.7, 8.8, 77.7, 195.7, 142.0, 230.8],
    "fused": [321.4, 5492.7, 29952.5, 30553.9, 36930.1, 98400.6],
    "fused_std": [72.1, 11.3, 86.2, 257.4, 227.6, 180.8],
    "speedup": [1.01, 1.00, 1.01, 1.02, 1.01, 1.02],
    "speedup_std": [0.01, 0.00, 0.00, 0.01, 0.00, 0.00],
    "bw_unfused": [0.0, 0.0, 0.0, 0.3, 2.2, 8.1],
    "bw_unfused_std": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    "bw_fused": [0.0, 0.0, 0.0, 0.1, 1.1, 4.2],
    "bw_fused_std": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
}

# ==============================================================================
# Map Reduce - Block-level Implementation
# (No data provided - fill in when available)
# ==============================================================================
MAP_REDUCE_BLOCK_FP32 = {
    "unfused": [6.9, 6.9, 9.6, 81.7, 821.3, 8389.6],
    "unfused_std": [0.3, 0.3, 0.1, 0.9, 5.1, 65.0],
    "fused": [4.4, 4.4, 7.0, 43.2, 462.0, 4806.3],
    "fused_std": [0.2, 0.2, 0.1, 0.5, 8.4, 88.1],
    "speedup": [1.58, 1.58, 1.36, 1.89, 1.78, 1.75],
    "speedup_std": [0.10, 0.08, 0.02, 0.02, 0.02, 0.02],
    "bw_unfused": [2.4, 23.9, 171.5, 200.6, 199.5, 195.3],
    "bw_unfused_std": [0.1, 1.1, 1.2, 2.1, 1.3, 1.5],
    "bw_fused": [1.9, 18.9, 116.7, 189.8, 177.4, 170.5],
    "bw_fused_std": [0.1, 0.8, 1.5, 2.2, 3.3, 3.2],
}

MAP_REDUCE_BLOCK_FP16 = {
    "unfused": [6.8, 6.6, 8.5, 66.2, 651.5, 6716.9],
    "unfused_std": [0.1, 0.1, 0.0, 0.9, 1.9, 20.9],
    "fused": [4.3, 4.2, 6.1, 42.9, 479.7, 4852.9],
    "fused_std": [0.1, 0.1, 0.0, 0.4, 1.2, 5.9],
    "speedup": [1.60, 1.58, 1.40, 1.55, 1.36, 1.38],
    "speedup_std": [0.04, 0.05, 0.01, 0.03, 0.00, 0.01],
    "bw_unfused": [1.2, 12.4, 96.0, 123.7, 125.7, 122.0],
    "bw_unfused_std": [0.0, 0.2, 0.5, 1.7, 0.4, 0.4],
    "bw_fused": [1.0, 9.7, 66.9, 95.6, 85.4, 84.4],
    "bw_fused_std": [0.0, 0.2, 0.2, 1.0, 0.2, 0.1],
}

# ==============================================================================
# Map Reduce - Mixed Precision Implementation - Naive
# ==============================================================================
MAP_REDUCE_MIXED_NAIVE = {
    "unfused": [7.3, 27.0, 225.3, 2134.4, 20491.7, 204906.9],
    "unfused_std": [1.4, 6.9, 50.5, 256.1, 1.1, 8.8],
    "fused": [5.1, 24.9, 221.6, 2030.8, 20280.9, 202778.4],
    "fused_std": [1.0, 5.4, 49.9, 0.5, 1.2, 4.6],
    "speedup": [1.43, 1.08, 1.02, 1.05, 1.01, 1.01],
    "speedup_std": [0.04, 0.03, 0.01, 0.13, 0.00, 0.00],
    "bw_unfused": [1.2, 3.2, 3.8, 3.9, 4.0, 4.0],
    "bw_unfused_std": [0.2, 0.5, 0.5, 0.4, 0.0, 0.0],
    "bw_fused": [0.8, 1.7, 1.9, 2.0, 2.0, 2.0],
    "bw_fused_std": [0.1, 0.2, 0.3, 0.0, 0.0, 0.0],
}

MAP_REDUCE_MIXED_BLOCK = {
    "unfused": [6.9, 6.8, 9.1, 62.8, 608.5, 6331.6],
    "unfused_std": [0.1, 0.1, 0.1, 0.4, 2.2, 53.4],
    "fused": [4.4, 4.3, 6.8, 40.6, 444.5, 4501.1],
    "fused_std": [0.3, 0.1, 0.1, 0.4, 7.8, 47.5],
    "speedup": [1.57, 1.59, 1.34, 1.55, 1.37, 1.41],
    "speedup_std": [0.10, 0.05, 0.03, 0.02, 0.02, 0.01],
    "bw_unfused": [1.2, 12.0, 90.2, 130.5, 134.6, 129.4],
    "bw_unfused_std": [0.0, 0.2, 0.7, 0.8, 0.5, 1.1],
    "bw_fused": [0.9, 9.6, 60.5, 100.9, 92.2, 91.0],
    "bw_fused_std": [0.1, 0.2, 0.8, 0.9, 1.7, 1.0],
}

# ==============================================================================
# Plot configuration (y_max values for consistent scaling)
# T4 has lower bandwidth (~300 GB/s) than RTX 3080 (~760 GB/s)
# ==============================================================================
PLOT_CONFIG = {
    "add": {"speedup_y_max": 2.5, "bandwidth_y_max": 500},
    "fma": {"speedup_y_max": 2.5, "bandwidth_y_max": 500},
    "relu": {"speedup_y_max": 3.5, "bandwidth_y_max": 500},
    "map_reduce_naive": {"speedup_y_max": 1.75, "bandwidth_y_max": 15, "use_log_scale": False},
    "map_reduce_block": {"speedup_y_max": 2.25, "bandwidth_y_max": 300},
    "map_reduce_mixed_naive": {"speedup_y_max": 1.75, "bandwidth_y_max": 10},
    "map_reduce_mixed_block": {"speedup_y_max": 1.75, "bandwidth_y_max": 300},
}
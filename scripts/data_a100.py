# NVIDIA A100-SXM4-40GB Benchmark Data
# 10 runs per configuration

GPU_NAME = "A100"
GPU_DISPLAY_NAME = "NVIDIA A100"

# ==============================================================================
# Element-wise Addition
# ==============================================================================
ADD_FP32 = {
    "unfused": [6.62, 6.53, 6.58, 11.85, 159.21, 1507.37],
    "unfused_std": [0.42, 0.12, 0.35, 1.01, 2.21, 3.04],
    "fused": [3.39, 3.23, 3.44, 5.96, 94.09, 897.92],
    "fused_std": [0.50, 0.09, 0.62, 0.52, 0.91, 0.83],
    "speedup": [1.97, 2.02, 1.95, 1.99, 1.69, 1.68],
    "speedup_std": [0.14, 0.06, 0.24, 0.05, 0.03, 0.00],
    "bw_unfused": [3.10, 31.39, 311.79, 1737.35, 1286.53, 1358.67],
    "bw_unfused_std": [0.17, 0.57, 14.64, 124.50, 17.45, 2.72],
    "bw_fused": [3.68, 38.08, 364.95, 2073.33, 1306.15, 1368.49],
    "bw_fused_std": [0.41, 1.04, 48.31, 147.87, 12.32, 1.27],
}

ADD_FP16 = {
    "unfused": [6.64, 6.52, 6.65, 11.35, 100.38, 936.26],
    "unfused_std": [0.44, 0.10, 0.49, 0.36, 1.09, 46.16],
    "fused": [3.24, 3.20, 3.37, 5.65, 52.47, 499.48],
    "fused_std": [0.11, 0.07, 0.25, 0.06, 0.10, 21.99],
    "speedup": [2.05, 2.03, 1.97, 2.01, 1.91, 1.88],
    "speedup_std": [0.12, 0.06, 0.07, 0.06, 0.02, 0.01],
    "bw_unfused": [1.55, 15.72, 154.61, 902.94, 1020.25, 1095.84],
    "bw_unfused_std": [0.09, 0.24, 10.42, 27.09, 10.88, 48.04],
    "bw_fused": [1.90, 19.18, 183.08, 1087.55, 1170.98, 1232.02],
    "bw_fused_std": [0.06, 0.42, 12.80, 11.24, 2.14, 48.81],
}

# ==============================================================================
# Fused Multiply-Add (FMA)
# ==============================================================================
FMA_FP32 = {
    "unfused": [6.45, 6.38, 6.40, 11.99, 187.31, 1796.19],
    "unfused_std": [0.17, 0.06, 0.08, 0.59, 0.98, 0.59],
    "fused": [3.25, 3.21, 3.31, 6.25, 123.03, 1183.38],
    "fused_std": [0.08, 0.08, 0.21, 0.36, 1.01, 1.14],
    "speedup": [1.99, 1.99, 1.94, 1.92, 1.52, 1.52],
    "speedup_std": [0.06, 0.05, 0.12, 0.13, 0.00, 0.00],
    "bw_unfused": [3.81, 38.53, 383.87, 2053.85, 1312.07, 1368.23],
    "bw_unfused_std": [0.10, 0.39, 4.67, 89.44, 6.80, 0.45],
    "bw_fused": [5.05, 51.04, 496.10, 2629.94, 1331.79, 1384.51],
    "bw_fused_std": [0.12, 1.23, 27.16, 133.69, 10.66, 1.33],
}

FMA_FP16 = {
    "unfused": [6.55, 6.67, 6.57, 11.48, 105.42, 997.56],
    "unfused_std": [0.33, 0.50, 0.44, 0.16, 1.70, 41.46],
    "fused": [3.28, 3.28, 3.52, 5.91, 65.74, 613.92],
    "fused_std": [0.20, 0.18, 0.69, 0.03, 0.04, 0.41],
    "speedup": [2.00, 2.03, 1.91, 1.94, 1.61, 1.62],
    "speedup_std": [0.04, 0.08, 0.23, 0.03, 0.03, 0.07],
    "bw_unfused": [1.88, 18.50, 187.64, 1070.46, 1165.87, 1233.54],
    "bw_unfused_std": [0.09, 1.25, 10.88, 14.42, 18.05, 46.40],
    "bw_fused": [2.51, 25.03, 239.15, 1386.76, 1246.20, 1334.37],
    "bw_fused_std": [0.14, 1.27, 35.49, 7.49, 0.78, 0.90],
}

# ==============================================================================
# ReLU
# ==============================================================================
RELU_FP32 = {
    "unfused": [9.67, 9.91, 9.80, 17.74, 223.01, 2113.66],
    "unfused_std": [0.10, 0.57, 0.50, 1.43, 2.22, 1.94],
    "fused": [3.46, 3.24, 3.38, 6.09, 94.11, 897.80],
    "fused_std": [0.64, 0.11, 0.28, 0.52, 0.57, 0.32],
    "speedup": [2.85, 3.05, 2.91, 2.91, 2.37, 2.35],
    "speedup_std": [0.37, 0.14, 0.16, 0.01, 0.02, 0.00],
    "bw_unfused": [2.97, 29.01, 293.30, 1623.81, 1285.81, 1356.51],
    "bw_unfused_std": [0.03, 1.49, 13.27, 109.15, 12.50, 1.24],
    "bw_fused": [3.63, 37.90, 366.00, 2027.30, 1305.68, 1368.68],
    "bw_fused_std": [0.47, 1.17, 28.29, 142.47, 7.83, 0.49],
}

RELU_FP16 = {
    "unfused": [9.63, 10.05, 9.90, 16.91, 146.02, 1368.25],
    "unfused_std": [0.08, 0.77, 0.53, 0.13, 0.21, 71.23],
    "fused": [3.23, 3.22, 3.25, 5.79, 52.80, 494.49],
    "fused_std": [0.09, 0.05, 0.16, 0.03, 0.14, 2.84],
    "speedup": [2.99, 3.13, 3.05, 2.92, 2.77, 2.77],
    "speedup_std": [0.08, 0.24, 0.15, 0.01, 0.01, 0.13],
    "bw_unfused": [1.49, 14.33, 145.20, 847.93, 981.77, 1050.03],
    "bw_unfused_std": [0.01, 1.00, 7.17, 6.69, 1.43, 48.30],
    "bw_fused": [1.91, 19.11, 189.31, 1061.69, 1163.61, 1242.54],
    "bw_fused_std": [0.05, 0.31, 8.25, 6.39, 3.03, 7.04],
}

# ==============================================================================
# Map Reduce - Naive Implementation
# (No data provided - fill in when available)
# ==============================================================================
MAP_REDUCE_NAIVE_FP32 = {
    "unfused": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    "unfused_std": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    "fused": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    "fused_std": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    "speedup": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    "speedup_std": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    "bw_unfused": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    "bw_unfused_std": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    "bw_fused": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    "bw_fused_std": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
}

MAP_REDUCE_NAIVE_FP16 = {
    "unfused": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    "unfused_std": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    "fused": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    "fused_std": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    "speedup": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    "speedup_std": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    "bw_unfused": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    "bw_unfused_std": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    "bw_fused": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    "bw_fused_std": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
}

# ==============================================================================
# Map Reduce - Block-level Implementation
# (No data provided - fill in when available)
# ==============================================================================
MAP_REDUCE_BLOCK_FP32 = {
    "unfused": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    "unfused_std": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    "fused": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    "fused_std": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    "speedup": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    "speedup_std": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    "bw_unfused": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    "bw_unfused_std": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    "bw_fused": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    "bw_fused_std": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
}

MAP_REDUCE_BLOCK_FP16 = {
    "unfused": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    "unfused_std": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    "fused": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    "fused_std": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    "speedup": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    "speedup_std": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    "bw_unfused": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    "bw_unfused_std": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    "bw_fused": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    "bw_fused_std": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
}

# ==============================================================================
# Plot configuration (y_max values for consistent scaling)
# A100 has high bandwidth (~1555 GB/s theoretical, ~1300-1400 GB/s achieved)
# ==============================================================================
PLOT_CONFIG = {
    "add": {"speedup_y_max": 2.5, "bandwidth_y_max": 2500},
    "fma": {"speedup_y_max": 2.5, "bandwidth_y_max": 3000},
    "relu": {"speedup_y_max": 3.5, "bandwidth_y_max": 2500},
    "map_reduce_naive": {"speedup_y_max": 1.75, "bandwidth_y_max": 20},
    "map_reduce_block": {"speedup_y_max": 2.25, "bandwidth_y_max": 500},
}